version: '3.7'

services:
  # Hadoop master
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.1.1-java8
    container_name: namenode
    ports:
      - 9870:9870
      - 8020:8020
    volumes:
      - ./namenode/home/${ADMIN_NAME:?err}:/home/${ADMIN_NAME:?err}
      - ./namenode/hadoop-data:/hadoop-data
      - ./namenode/entrypoint.sh:/entrypoint.sh
      - hadoop_namenode:/hadoop/dfs/name
    env_file:
      - ./hadoop.env
      - .env
    networks:
      - hadoop

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.1.1-java8
    container_name: resourcemanager
    ports:
      - 8088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop

  # Hadoop slave 1
  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.1.1-java8
    container_name: datanode1
    volumes:
      - hadoop_datanode_1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.1.1-java8
    container_name: nodemanager1
    volumes:
      - ./nodemanagers/entrypoint.sh:/entrypoint.sh
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
      - .env
    networks:
      - hadoop

  # Hadoop slave 2
  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.1.1-java8
    container_name: datanode2
    volumes:
      - hadoop_datanode_2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop

  nodemanager2:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.1.1-java8
    container_name: nodemanager2
    volumes:
      - ./nodemanagers/entrypoint.sh:/entrypoint.sh
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode2:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
      - .env
    networks:
      - hadoop

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.1.1-java8
    container_name: historyserver
    ports:
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks:
      - hadoop

  # HUE (Management node, similar to Ambari)
  hue:
    container_name: hue
    image: gethue/hue:4.4.0
    ports:
      - 8000:8888
    env_file:
      - ./hadoop.env
    volumes:
      - ./hue/hue-overrides.ini:/usr/share/hue/desktop/conf/hue-overrides.ini
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - hadoop

  hue-db:
    # TODO: Rename hue_host to hue-db. Also in hue-overrides.ini and in hue service
    container_name: hue_host
    restart: always
    image: postgres:11.9
    environment:
      - POSTGRES_USER=hue_user
      - POSTGRES_PASSWORD=secret
      - POSTGRES_DB=hue_db
    ports:
      - 5432:5432
    volumes:
      - hadoop_postgres:/var/lib/postgresql/data
      - ./hue-db/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - hadoop

  # HIVE
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hiveserver
    env_file:
      - ./hadoop.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    networks:
      - hadoop

  hive-metastore:
    container_name: hivemetastore
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop.env
    command: /opt/hive/bin/hive --service metastore
    networks:
      - hadoop
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode1:9864 datanode2:9864 hive-metastore-postgresql:5432"

  hive-metastore-postgresql:
    container_name: hivedb
    image: bde2020/hive-metastore-postgresql:2.3.0
    networks:
      - hadoop

  presto-coordinator:
    container_name: presto
    image: shawnzhu/prestodb:0.181
    networks:
      - hadoop
  
  # Spark
  spark-master:
    image: bde2020/spark-master:2.3.2-hadoop3.1.1-java8
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop.env
    networks: 
      - hadoop

  spark-worker-1:
    image:  bde2020/spark-worker:2.3.2-hadoop3.1.1-java8
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - 8081:8081
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    env_file:
      - ./hadoop.env
    networks: 
      - hadoop
  
  spark-worker-2:
    image:  bde2020/spark-worker:2.3.2-hadoop3.1.1-java8
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - 8082:8081
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    env_file:
      - ./hadoop.env
    networks: 
      - hadoop

  zeppelin:
    build: ./zeppelin
    ports:
      - 8083:8080
    volumes:
      - ./notebook:/opt/zeppelin/notebook
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - SPARK_MASTER=spark://spark-master:7077
      - MASTER=spark://spark-master:7077
      #SPARK_SUBMIT_OPTIONS: "--jars /opt/sansa-examples/jars/sansa-examples-spark-2016-12.jar"
    depends_on:
      spark-master:
        condition: service_healthy
      namenode:
        condition: service_healthy
    networks:
      - hadoop

networks:
  hadoop:

volumes:
  hadoop_namenode:
  hadoop_datanode_1:
  hadoop_datanode_2:
  hadoop_historyserver:
  hadoop_postgres:
